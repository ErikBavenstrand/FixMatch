{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvgL6VOouCx8"
   },
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Rn1mpsoBuCWz",
    "outputId": "7819c3fc-c00f-4edc-b223-ceaf78701105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: GeForce GTX 1070 (UUID: GPU-bf715867-ba4f-a5ff-9f1b-6f63f6a0a2f0)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkXbsznM3DRm"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "2a_aYlW4zx32",
    "outputId": "9ea560f5-7668-45b0-b1fc-93b170d6f1a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-addons in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied, skipping upgrade: typeguard>=2.7 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from tensorflow-addons) (2.9.1)\n",
      "Requirement already satisfied: tqdm in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (4.28.1)\n",
      "Requirement already satisfied: livelossplot in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (0.5.3)\n",
      "Requirement already satisfied: ipython in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from livelossplot) (7.14.0)\n",
      "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from livelossplot) (3.2.1)\n",
      "Requirement already satisfied: bokeh; python_version >= \"3.6\" in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from livelossplot) (2.2.2)\n",
      "Requirement already satisfied: decorator in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (4.4.2)\n",
      "Requirement already satisfied: backcall in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (41.2.0)\n",
      "Requirement already satisfied: pygments in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (2.6.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (3.0.5)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (0.17.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (4.3.3)\n",
      "Requirement already satisfied: pickleshare in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from ipython->livelossplot) (0.7.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.18.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.11.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (3.7.4.3)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (20.4)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (7.1.2)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (6.0.4)\n",
      "Requirement already satisfied: wcwidth in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->livelossplot) (0.1.9)\n",
      "Requirement already satisfied: parso>=0.7.0 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from jedi>=0.10->ipython->livelossplot) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: six in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from traitlets>=4.2->ipython->livelossplot) (1.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/erikb/.pyenv/versions/3.8.2/envs/sci/lib/python3.8/site-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img, array_to_img\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Dropout, GlobalAveragePooling2D, Dense, Softmax, Activation, MaxPooling2D, Flatten, AveragePooling2D\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "!pip install -U tensorflow-addons\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "#!pip install https://github.com/chengs/tqdm/archive/colab.zip\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "!pip install livelossplot\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKvDXVTDuXxN"
   },
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RvyI-fDxuXin"
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "CHANNELS = 3\n",
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, CHANNELS)\n",
    "CLASSES = 10\n",
    "TOTAL_NUM_TRAIN_SAMPLES = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjDgrzHkwx0T"
   },
   "source": [
    "# Data & Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "E0D2ihlN1Mfu"
   },
   "outputs": [],
   "source": [
    "##########\n",
    "# Cutout #\n",
    "##########\n",
    "def cutout(image):\n",
    "    size = tf.cast(tf.random.uniform([], minval=0, maxval=0.5) * IMG_WIDTH, tf.int32)\n",
    "    if size <= 0:\n",
    "        return image\n",
    "\n",
    "    height_loc = tf.random.uniform([], minval=0, maxval=IMG_WIDTH, dtype=tf.int32)\n",
    "    width_loc = tf.random.uniform([], minval=0, maxval=IMG_HEIGHT, dtype=tf.int32)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    image = tfa.image.random_cutout(image, size)\n",
    "    return tf.squeeze(image)\n",
    "\n",
    "######################\n",
    "# Weak augmentations #\n",
    "######################\n",
    "def shift(image):\n",
    "    pixels = tf.cast(\n",
    "        tf.random.uniform([], minval=-0.125, maxval=0.125) * IMG_WIDTH, tf.int32)\n",
    "    return tf.roll(image, [pixels, pixels], [0, 1])\n",
    "\n",
    "def mirror(image):\n",
    "    return tf.image.random_flip_left_right(image)\n",
    "\n",
    "########################\n",
    "# Strong augmentations #\n",
    "########################\n",
    "def autocontrast(image):\n",
    "    def scale_channel(channel):\n",
    "        lo = tf.cast(tf.reduce_min(channel), tf.float32)\n",
    "        hi = tf.cast(tf.reduce_max(channel), tf.float32)\n",
    "\n",
    "        def scale_values(im):\n",
    "            scale = 255.0 / (hi - lo)\n",
    "            offset = -lo * scale\n",
    "            im = tf.cast(im, tf.float32) * scale + offset\n",
    "            return tf.saturate_cast(im, tf.uint8)\n",
    "\n",
    "        result = tf.cond(hi > lo, lambda: scale_values(channel),\n",
    "                         lambda: channel)\n",
    "        return result\n",
    "\n",
    "    s1 = scale_channel(image[:, :, 0])\n",
    "    s2 = scale_channel(image[:, :, 1])\n",
    "    s3 = scale_channel(image[:, :, 2])\n",
    "    image = tf.stack([s1, s2, s3], 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "def brightness(image):\n",
    "    factor = tf.random.uniform([], minval=0.05, maxval=0.95)\n",
    "    degenerate = tf.zeros_like(image)\n",
    "    return blend(degenerate, image, factor)\n",
    "\n",
    "\n",
    "def color(image):\n",
    "    factor = tf.random.uniform([], minval=0.05, maxval=0.95)\n",
    "    degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n",
    "    return blend(degenerate, image, factor)\n",
    "\n",
    "\n",
    "def contrast(image):\n",
    "    factor = tf.random.uniform([], minval=0.05, maxval=0.95)\n",
    "    grayscale_im = tf.image.rgb_to_grayscale(image)\n",
    "    mean = tf.reduce_mean(tf.cast(grayscale_im, tf.float32))\n",
    "    mean = tf.saturate_cast(mean + 0.5, tf.uint8)\n",
    "\n",
    "    degenerate = tf.ones_like(grayscale_im, dtype=tf.uint8) * mean\n",
    "    degenerate = tf.image.grayscale_to_rgb(degenerate)\n",
    "\n",
    "    return blend(degenerate, image, factor)\n",
    "\n",
    "\n",
    "def equalize(image):\n",
    "    def scale_channel(im, c):\n",
    "        im = tf.cast(im[:, :, c], tf.int32)\n",
    "\n",
    "        histo = tf.histogram_fixed_width(im, [0, 255], nbins=256)\n",
    "\n",
    "        nonzero = tf.where(tf.not_equal(histo, 0))\n",
    "        nonzero_histo = tf.reshape(tf.gather(histo, nonzero), [-1])\n",
    "        step = (tf.reduce_sum(nonzero_histo) - nonzero_histo[-1]) // 255\n",
    "\n",
    "        def build_lut(histo, step):\n",
    "            lut = (tf.cumsum(histo) + (step // 2)) // step\n",
    "            lut = tf.concat([[0], lut[:-1]], 0)\n",
    "            return tf.clip_by_value(lut, 0, 255)\n",
    "\n",
    "        result = tf.cond(tf.equal(step, 0), lambda: im,\n",
    "                         lambda: tf.gather(build_lut(histo, step), im))\n",
    "\n",
    "        return tf.cast(result, tf.uint8)\n",
    "\n",
    "    s1 = scale_channel(image, 0)\n",
    "    s2 = scale_channel(image, 1)\n",
    "    s3 = scale_channel(image, 2)\n",
    "    image = tf.stack([s1, s2, s3], 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "def identity(image):\n",
    "    return image\n",
    "\n",
    "\n",
    "def posterize(image):\n",
    "    bits = tf.random.uniform([], minval=4, maxval=9, dtype=tf.int32)\n",
    "    shift = tf.cast(8 - bits, image.dtype)\n",
    "    return tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
    "\n",
    "\n",
    "def rotate(image):\n",
    "    degrees = tf.random.uniform([], minval=-30, maxval=30)\n",
    "    degrees_to_radians = math.pi / 180.0\n",
    "    radians = degrees * degrees_to_radians\n",
    "\n",
    "    image = tfa.image.transform_ops.rotate(wrap(image), radians)\n",
    "    return unwrap(image)\n",
    "\n",
    "\n",
    "def sharpness(image):\n",
    "    factor = tf.random.uniform([], minval=0.05, maxval=0.95)\n",
    "    orig_im = image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    kernel = tf.constant([[1, 1, 1], [1, 5, 1], [1, 1, 1]],\n",
    "                         dtype=tf.float32,\n",
    "                         shape=[3, 3, 1, 1]) / 13.\n",
    "    kernel = tf.tile(kernel, [1, 1, 3, 1])\n",
    "    strides = [1, 1, 1, 1]\n",
    "    degenerate = tf.nn.depthwise_conv2d(image,\n",
    "                                        kernel,\n",
    "                                        strides,\n",
    "                                        padding='VALID',\n",
    "                                        dilations=[1, 1])\n",
    "    degenerate = tf.squeeze(tf.saturate_cast(degenerate, tf.uint8), [0])\n",
    "\n",
    "    mask = tf.ones_like(degenerate)\n",
    "    padded_mask = tf.pad(mask, [[1, 1], [1, 1], [0, 0]])\n",
    "    padded_degenerate = tf.pad(degenerate, [[1, 1], [1, 1], [0, 0]])\n",
    "    result = tf.where(tf.equal(padded_mask, 1), padded_degenerate, orig_im)\n",
    "\n",
    "    return blend(result, orig_im, factor)\n",
    "\n",
    "\n",
    "def shear_x(image):\n",
    "    level = tf.random.uniform([], minval=-0.3, maxval=0.3)\n",
    "    image = tfa.image.transform_ops.transform(\n",
    "        wrap(image), [1., level, 0., 0., 1., 0., 0., 0.])\n",
    "    return unwrap(image)\n",
    "\n",
    "\n",
    "def shear_y(image):\n",
    "    level = tf.random.uniform([], minval=-0.3, maxval=0.3)\n",
    "    image = tfa.image.transform_ops.transform(\n",
    "        wrap(image), [1., 0., 0., level, 1., 0., 0., 0.])\n",
    "    return unwrap(image)\n",
    "\n",
    "\n",
    "def solarize(image):\n",
    "    threshold = tf.random.uniform([], minval=0, maxval=255, dtype=tf.int32)\n",
    "    threshold = tf.saturate_cast(threshold, image.dtype)\n",
    "    return tf.where(image < threshold, image, 255 - image)\n",
    "\n",
    "\n",
    "def translate_x(image):\n",
    "    pixels = tf.cast(\n",
    "        tf.random.uniform([], minval=-0.3, maxval=0.3) * IMG_WIDTH, tf.int32)\n",
    "    image = tf.roll(image, [0, pixels], tf.constant([0, 1]))\n",
    "    return image\n",
    "\n",
    "\n",
    "def translate_y(image):\n",
    "    pixels = tf.cast(\n",
    "        tf.random.uniform([], minval=-0.3, maxval=0.3) * IMG_HEIGHT, tf.int32)\n",
    "    image = tf.roll(image, [pixels, 0], tf.constant([0, 1]))\n",
    "    return image\n",
    "\n",
    "###########\n",
    "# Utility #\n",
    "###########\n",
    "def blend(image1, image2, factor):\n",
    "    image1 = tf.cast(image1, tf.float32)\n",
    "    image2 = tf.cast(image2, tf.float32)\n",
    "    return tf.saturate_cast(image1 + factor * (image2 - image1), tf.uint8)\n",
    "\n",
    "\n",
    "def wrap(image):\n",
    "    shape = tf.shape(image)\n",
    "    extended_channel = tf.ones([shape[0], shape[1], 1], image.dtype)\n",
    "    extended = tf.concat([image, extended_channel], 2)\n",
    "    return extended\n",
    "\n",
    "\n",
    "def unwrap(image):\n",
    "    image_shape = tf.shape(image)\n",
    "    flattened_image = tf.reshape(image, [-1, image_shape[2]])\n",
    "\n",
    "    alpha_channel = tf.expand_dims(flattened_image[:, image_shape[2] - 1], 1)\n",
    "\n",
    "    replace = tf.constant([128, 128, 128, 1], image.dtype)\n",
    "\n",
    "    flattened_image = tf.where(\n",
    "        tf.equal(alpha_channel, 0),\n",
    "        tf.ones_like(flattened_image, dtype=image.dtype) * replace,\n",
    "        flattened_image)\n",
    "\n",
    "    image = tf.reshape(flattened_image, image_shape)\n",
    "    image = tf.slice(image, [0, 0, 0], [image_shape[0], image_shape[1], image_shape[2] - 1])\n",
    "    return image\n",
    "\n",
    "####################################\n",
    "# Augmentation selection functions #\n",
    "####################################\n",
    "def any_equals(x, y, v):\n",
    "    return x == v or y == v\n",
    "\n",
    "\n",
    "def augment_image_strong(image):\n",
    "    num_funcs = tf.constant(14, dtype=tf.int32)\n",
    "    func_num1 = tf.random.uniform([],\n",
    "                                  minval=0,\n",
    "                                  maxval=num_funcs,\n",
    "                                  dtype=tf.int32)\n",
    "    func_num2 = tf.random.uniform([],\n",
    "                                  minval=0,\n",
    "                                  maxval=num_funcs,\n",
    "                                  dtype=tf.int32)\n",
    "\n",
    "    while func_num1 == func_num2:\n",
    "        func_num2 = tf.random.uniform([],\n",
    "                                      minval=0,\n",
    "                                      maxval=num_funcs,\n",
    "                                      dtype=tf.int32)\n",
    "\n",
    "    if any_equals(func_num1, func_num2, 0):\n",
    "        image = autocontrast(image)\n",
    "    if any_equals(func_num1, func_num2, 1):\n",
    "        image = brightness(image)\n",
    "    if any_equals(func_num1, func_num2, 2):\n",
    "        image = color(image)\n",
    "    if any_equals(func_num1, func_num2, 3):\n",
    "        image = contrast(image)\n",
    "    if any_equals(func_num1, func_num2, 4):\n",
    "        image = equalize(image)\n",
    "    if any_equals(func_num1, func_num2, 5):\n",
    "        image = identity(image)\n",
    "    if any_equals(func_num1, func_num2, 6):\n",
    "        image = posterize(image)\n",
    "    if any_equals(func_num1, func_num2, 7):\n",
    "        image = rotate(image)\n",
    "    if any_equals(func_num1, func_num2, 8):\n",
    "        image = sharpness(image)\n",
    "    if any_equals(func_num1, func_num2, 9):\n",
    "        image = shear_x(image)\n",
    "    if any_equals(func_num1, func_num2, 10):\n",
    "        image = shear_y(image)\n",
    "    if any_equals(func_num1, func_num2, 11):\n",
    "        image = solarize(image)\n",
    "    if any_equals(func_num1, func_num2, 12):\n",
    "        image = translate_x(image)\n",
    "    if any_equals(func_num1, func_num2, 13):\n",
    "        image = translate_y(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def augment_image_weak(image):\n",
    "    image = shift(image)\n",
    "    image = mirror(image)\n",
    "    return image\n",
    "\n",
    "#####################\n",
    "# Dataset splitting #\n",
    "#####################\n",
    "def x_u_split_idx(labels, num_labels_per_class):\n",
    "    num_classes = 10\n",
    "    labeled = []\n",
    "    unlabeled = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        idx = np.where(labels == i)[0]\n",
    "        np.random.shuffle(idx)\n",
    "        labeled.extend(idx[:num_labels_per_class])\n",
    "        unlabeled.extend(idx)\n",
    "\n",
    "    np.random.shuffle(labeled)\n",
    "    np.random.shuffle(unlabeled)\n",
    "    return labeled, unlabeled\n",
    "\n",
    "\n",
    "def train_val_split(inputs, outputs, num_validation):\n",
    "    num_classes = 10\n",
    "    num_validation_per_class = num_validation // num_classes\n",
    "    train_idx = []\n",
    "    validation_idx = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        idx = np.where(outputs == i)[0]\n",
    "        np.random.shuffle(idx)\n",
    "        train_idx.extend(idx[num_validation_per_class:])\n",
    "        validation_idx.extend(idx[:num_validation_per_class])\n",
    "\n",
    "    x_train = inputs[train_idx]\n",
    "    y_train = outputs[train_idx]\n",
    "\n",
    "    x_validation = inputs[validation_idx]\n",
    "    y_validation = outputs[validation_idx]\n",
    "\n",
    "    return (x_train, y_train), (x_validation, y_validation)\n",
    "\n",
    "#################################\n",
    "# Generate Train & Val Datasets #\n",
    "#################################\n",
    "def dataset_trainval(num_labels_per_class, batch_size, mu, validation_samples):\n",
    "    (x_train, y_train), _ = tf.keras.datasets.cifar10.load_data()\n",
    "    (x_train, y_train), (x_validation, y_validation) = train_val_split(x_train, y_train, validation_samples)\n",
    "    (labeled_idx, unlabeled_idx) = x_u_split_idx(y_train, num_labels_per_class)\n",
    "    \n",
    "    total_batch_size = batch_size * (mu + 1)\n",
    "    n_labeled_batches = math.ceil(num_labels_per_class * CLASSES / batch_size)\n",
    "    n_unlabeled_batches = math.ceil(x_train.shape[0] / (batch_size * mu))\n",
    "    n_val_batches = math.ceil(x_validation.shape[0] / total_batch_size)\n",
    "\n",
    "    # Labeled\n",
    "    y_labeled = tf.one_hot(y_train[labeled_idx].flatten(), CLASSES, dtype=tf.uint8)\n",
    "    y_labeled = tf.data.Dataset.from_tensor_slices(y_labeled)\n",
    "    x_labeled = x_train[labeled_idx]\n",
    "    x_labeled = tf.data.Dataset.from_tensor_slices(x_labeled)\n",
    "    x_labeled = x_labeled.map(augment_image_weak, num_parallel_calls=AUTO)\n",
    "    x_labeled = x_labeled.map(lambda x: tf.clip_by_value(x / 255, 0, 1), num_parallel_calls=AUTO)\n",
    "    labeled = tf.data.Dataset.zip((x_labeled, y_labeled)).shuffle(batch_size * 8).batch(batch_size).repeat()\n",
    "\n",
    "    # Unlabeled\n",
    "    w_unlabeled = x_train[unlabeled_idx]\n",
    "    w_unlabeled = tf.data.Dataset.from_tensor_slices(w_unlabeled)\n",
    "    w_unlabeled = w_unlabeled.map(augment_image_weak,\n",
    "                                  num_parallel_calls=AUTO)\n",
    "    w_unlabeled = w_unlabeled.map(lambda x: tf.clip_by_value(x / 255, 0, 1),\n",
    "                                  num_parallel_calls=AUTO)\n",
    "    s_unlabeled = x_train[unlabeled_idx]\n",
    "    s_unlabeled = tf.data.Dataset.from_tensor_slices(s_unlabeled)\n",
    "    s_unlabeled = s_unlabeled.map(augment_image_strong,\n",
    "                                  num_parallel_calls=AUTO)\n",
    "    s_unlabeled = s_unlabeled.map(cutout, num_parallel_calls=AUTO)\n",
    "    s_unlabeled = s_unlabeled.map(lambda x: tf.clip_by_value(x / 255, 0, 1),\n",
    "                                  num_parallel_calls=AUTO)\n",
    "    unlabeled = tf.data.Dataset.zip(\n",
    "        (w_unlabeled, s_unlabeled)).shuffle(batch_size * mu * 8).batch(\n",
    "            batch_size * mu).repeat()\n",
    "\n",
    "    # Validation\n",
    "    y_validation = tf.one_hot(y_validation.flatten(), CLASSES, dtype=tf.uint8)\n",
    "    y_validation = tf.data.Dataset.from_tensor_slices(y_validation)\n",
    "    x_validation = tf.data.Dataset.from_tensor_slices(x_validation)\n",
    "    x_validation = x_validation.map(augment_image_weak,\n",
    "                                    num_parallel_calls=AUTO)\n",
    "    x_validation = x_validation.map(lambda x: tf.clip_by_value(x / 255, 0, 1),\n",
    "                                    num_parallel_calls=AUTO)\n",
    "    validation = tf.data.Dataset.zip(\n",
    "        (x_validation, y_validation)).shuffle(total_batch_size * 8).batch(total_batch_size).repeat()\n",
    "\n",
    "    return (labeled, n_labeled_batches), (unlabeled, n_unlabeled_batches), (validation, n_val_batches)\n",
    "\n",
    "################################\n",
    "# Generate Reular Test Dataset #\n",
    "################################\n",
    "def dataset_test(batch_size):\n",
    "    _, (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    \n",
    "    n_test_batches = math.ceil(x_test.shape[0] / batch_size)\n",
    "\n",
    "    # Test\n",
    "    y_test_ds = tf.one_hot(y_test.flatten(), CLASSES, dtype=tf.uint8)\n",
    "    y_test_ds = tf.data.Dataset.from_tensor_slices(y_test_ds)\n",
    "    x_test_ds = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "    x_test_ds = x_test_ds.map(augment_image_weak, num_parallel_calls=AUTO)\n",
    "    x_test_ds = x_test_ds.map(lambda x: tf.clip_by_value(x / 255, 0, 1),\n",
    "                        num_parallel_calls=AUTO)\n",
    "    test = tf.data.Dataset.zip(\n",
    "        (x_test_ds, y_test_ds)).shuffle(batch_size * 8).batch(batch_size).repeat()\n",
    "\n",
    "    return (test, n_test_batches)\n",
    "\n",
    "##################################\n",
    "# Generate Grad-CAM Test Dataset #\n",
    "##################################\n",
    "def dataset_test_gradcam(batch_size):\n",
    "    _, (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "    n_test_grad_batches = math.ceil(x_test.shape[0] / batch_size)\n",
    "\n",
    "    # Test Grad-CAM\n",
    "    y_test_grad = tf.one_hot(y_test.flatten(), CLASSES, dtype=tf.uint8)\n",
    "    y_test_grad = tf.data.Dataset.from_tensor_slices(y_test_grad)\n",
    "    x_test_grad_w = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "    x_test_grad_w = x_test_grad_w.map(augment_image_weak, num_parallel_calls=AUTO)\n",
    "    x_test_grad_w = x_test_grad_w.map(lambda x: tf.clip_by_value(x / 255, 0, 1),\n",
    "                        num_parallel_calls=AUTO)\n",
    "    x_test_grad_s = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "    x_test_grad_s = x_test_grad_s.map(augment_image_strong, num_parallel_calls=AUTO)\n",
    "    x_test_grad_s = x_test_grad_s.map(cutout, num_parallel_calls=AUTO)\n",
    "    x_test_grad_s = x_test_grad_s.map(lambda x: tf.clip_by_value(x / 255, 0, 1),\n",
    "                        num_parallel_calls=AUTO)\n",
    "    test_grad = tf.data.Dataset.zip(\n",
    "        (x_test_grad_w, x_test_grad_s, y_test_grad)).shuffle(batch_size * 8).batch(batch_size).repeat()\n",
    "\n",
    "    return (test_grad, n_test_grad_batches)\n",
    "\n",
    "#######################################\n",
    "# Generate Majority Vote Test Dataset #\n",
    "#######################################\n",
    "def dataset_test_vote(batch_size, repeats):\n",
    "    _, (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    \n",
    "    n_repeats_batch_size = math.floor(batch_size / repeats) * repeats\n",
    "    n_test_repeat_batches = math.ceil(x_test.shape[0] * repeats / n_repeats_batch_size)\n",
    "\n",
    "    # Test Voting\n",
    "    y_test_repeat = np.repeat(y_test, repeats, axis=0)\n",
    "    y_test_ds_repeat = tf.one_hot(y_test_repeat.flatten(), CLASSES, dtype=tf.uint8)\n",
    "    y_test_ds_repeat = tf.data.Dataset.from_tensor_slices(y_test_ds_repeat)\n",
    "    x_test_repeat = np.repeat(x_test, repeats, axis=0)\n",
    "    x_test_ds_repeat = tf.data.Dataset.from_tensor_slices(x_test_repeat)\n",
    "    x_test_ds_repeat = x_test_ds_repeat.map(augment_image_weak, num_parallel_calls=AUTO)\n",
    "    x_test_ds_repeat = x_test_ds_repeat.map(lambda x: tf.clip_by_value(x / 255, 0, 1),\n",
    "                        num_parallel_calls=AUTO)\n",
    "    test_repeat = tf.data.Dataset.zip(\n",
    "        (x_test_ds_repeat, y_test_ds_repeat)).batch(n_repeats_batch_size).shuffle(5).repeat()\n",
    "\n",
    "    return (test_repeat, n_test_repeat_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlLJ1KxztOWh"
   },
   "source": [
    "# Wide-ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AONji9sV4Idm"
   },
   "outputs": [],
   "source": [
    "def WideResNet(depth=28, widen_factor=2):\n",
    "    filters = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
    "    strides = [1, 2, 2]\n",
    "    assert ((depth - 4) % 6 == 0)\n",
    "    n = (depth - 4) // 6\n",
    "\n",
    "    inputs = Input(shape=IMG_SHAPE)\n",
    "    x = Conv2D(filters[0],\n",
    "               kernel_size=3,\n",
    "               strides=1,\n",
    "               padding='same',\n",
    "               use_bias=False)(inputs)\n",
    "\n",
    "    first_x = x\n",
    "    orig_x = x\n",
    "\n",
    "    for block_num in range(1, 4):\n",
    "        activate_before_residual = True if block_num == 1 else False\n",
    "        x = residual_block(x,\n",
    "                           filters[block_num - 1],\n",
    "                           filters[block_num],\n",
    "                           strides[block_num - 1],\n",
    "                           activate_before_residual=activate_before_residual)\n",
    "\n",
    "        for i in range(1, n):\n",
    "            x = residual_block(x,\n",
    "                               filters[block_num],\n",
    "                               filters[block_num],\n",
    "                               1,\n",
    "                               activate_before_residual=False)\n",
    "\n",
    "        x, orig_x = res_add(filters[block_num - 1], filters[block_num],\n",
    "                             strides[block_num - 1], x, orig_x)\n",
    "\n",
    "    x, _ = res_add(filters[0], filters[3], np.prod(strides), x, first_x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.999, scale=False, fused=True)(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(CLASSES)(x)\n",
    "    x = Softmax()(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def residual_block(x,\n",
    "                   in_filter,\n",
    "                   out_filter,\n",
    "                   stride,\n",
    "                   activate_before_residual=False):\n",
    "    if activate_before_residual:\n",
    "        x = BatchNormalization(momentum=0.999, scale=False, fused=True)(x)\n",
    "        x = ReLU()(x)\n",
    "        orig_x = x\n",
    "    else:\n",
    "        orig_x = x\n",
    "\n",
    "    block_x = x\n",
    "    if not activate_before_residual:\n",
    "        block_x = BatchNormalization(momentum=0.999, scale=False,\n",
    "                                     fused=True)(block_x)\n",
    "        block_x = ReLU()(block_x)\n",
    "\n",
    "    block_x = Conv2D(out_filter,\n",
    "                     kernel_size=3,\n",
    "                     strides=stride,\n",
    "                     padding='same',\n",
    "                     use_bias=False)(block_x)\n",
    "\n",
    "    block_x = BatchNormalization(momentum=0.999, scale=False,\n",
    "                                 fused=True)(block_x)\n",
    "    block_x = ReLU()(block_x)\n",
    "    block_x = Conv2D(out_filter,\n",
    "                     kernel_size=3,\n",
    "                     strides=1,\n",
    "                     padding='same',\n",
    "                     use_bias=False)(block_x)\n",
    "\n",
    "    if in_filter != out_filter:\n",
    "        kernel = stride_arr(stride, stride)\n",
    "        strides = stride_arr(stride, stride)\n",
    "        orig_x = tf.nn.avg_pool(orig_x,\n",
    "                                ksize=kernel,\n",
    "                                strides=strides,\n",
    "                                padding='VALID',\n",
    "                                data_format='NHWC')\n",
    "        orig_x = tf.pad(orig_x, [[0, 0], [0, 0], [0, 0],\n",
    "                                 [(out_filter - in_filter) // 2,\n",
    "                                  (out_filter - in_filter) // 2]])\n",
    "\n",
    "    x = orig_x + block_x\n",
    "    return x\n",
    "\n",
    "\n",
    "def res_add(in_filter, out_filter, stride, x, orig_x):\n",
    "    if in_filter != out_filter:\n",
    "        kernel = stride_arr(stride, stride)\n",
    "        strides = stride_arr(stride, stride)\n",
    "        orig_x = tf.nn.avg_pool(orig_x,\n",
    "                                ksize=kernel,\n",
    "                                strides=strides,\n",
    "                                padding='VALID',\n",
    "                                data_format='NHWC')\n",
    "        orig_x = tf.pad(orig_x, [[0, 0], [0, 0], [0, 0],\n",
    "                                 [(out_filter - in_filter) // 2,\n",
    "                                  (out_filter - in_filter) // 2]])\n",
    "\n",
    "    x = x + orig_x\n",
    "    orig_x = x\n",
    "    return x, orig_x\n",
    "\n",
    "\n",
    "def stride_arr(stride_h, stride_w):\n",
    "    return [1, stride_h, stride_w, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYhGszQVVo1D"
   },
   "source": [
    "# Training/Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L4LWTa_KAXLm"
   },
   "outputs": [],
   "source": [
    "def save_download_model(iteration):\n",
    "    model_name = 'model_' + str(iteration)\n",
    "    model_name_compressed = 'model_' + str(iteration) + '.zip'\n",
    "    model.save(model_name)\n",
    "    !zip -r $model_name_compressed $model_name\n",
    "\n",
    "def save_download_stats(train_losses_labeled, train_losses_unlabeled, train_losses, val_losses, val_accuracies, name='final'):\n",
    "    file_name = 'stats_' + name + '.npz'\n",
    "    np.savez_compressed(file_name, tll=train_losses_labeled, tlu=train_losses_unlabeled, tl=train_losses, vl=val_losses, va=val_accuracies)\n",
    "\n",
    "@tf.function\n",
    "def train_step(x_labeled, y_labeled, w_unlabeled, s_unlabeled):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Logits\n",
    "        logits_labeled = model(x_labeled, training=True)\n",
    "        logits_w_unlabeled = model(w_unlabeled, training=True)\n",
    "        logits_s_unlabeled = model(s_unlabeled, training=True)\n",
    "\n",
    "        # Labeled loss\n",
    "        loss_labeled = tf.keras.losses.categorical_crossentropy(y_labeled, logits_labeled)\n",
    "        loss_labeled = tf.reduce_mean(loss_labeled)\n",
    "\n",
    "        # Unlabeled loss\n",
    "        pseudo_labels = tf.stop_gradient(logits_w_unlabeled)\n",
    "        loss_unlabeled = tf.keras.losses.categorical_crossentropy(\n",
    "            tf.one_hot(tf.argmax(pseudo_labels, axis=-1), CLASSES, dtype=tf.int8),\n",
    "            logits_s_unlabeled)\n",
    "        pseudo_mask = (tf.reduce_max(pseudo_labels, axis=1) >= TAU)\n",
    "        pseudo_mask = tf.cast(pseudo_mask, tf.float32)\n",
    "        loss_unlabeled = tf.reduce_mean(loss_unlabeled * pseudo_mask)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = loss_labeled + LAMBDA_U * loss_unlabeled\n",
    "\n",
    "    grads = tape.gradient(total_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss_labeled, loss_unlabeled, total_loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def validation_step(x_validation, y_validation):\n",
    "    logits = model(x_validation, training=False)\n",
    "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_validation, logits))\n",
    "    predictions = tf.argmax(logits, axis=-1)\n",
    "    targets = tf.argmax(y_validation, axis=-1)\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(tf.equal(predictions, targets), tf.float32))\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(x_test, y_test):\n",
    "    logits = model(x_test, training=False)\n",
    "    predictions = tf.argmax(logits, axis=-1)\n",
    "    targets = tf.argmax(y_test, axis=-1)\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(tf.equal(predictions, targets), tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def lr_schedule(k):\n",
    "    return LR * tf.cos(\n",
    "        (7 * math.pi * k) / (16 * ITERATIONS))\n",
    "\n",
    "\n",
    "def run_train(labeled, unlabeled, validation, plotlosses=None, model_name='final'):\n",
    "    # Progress bar\n",
    "    pbar = tqdm(range(ITERATIONS))\n",
    "\n",
    "    # Statistics\n",
    "    train_losses_labeled = np.zeros((ITERATIONS))\n",
    "    train_losses_unlabeled = np.zeros((ITERATIONS))\n",
    "    train_losses = np.zeros((ITERATIONS))\n",
    "    val_losses = np.zeros((math.ceil(ITERATIONS / VAL_PRINT_STEP)))\n",
    "    val_accuracies = np.zeros((math.ceil(ITERATIONS / VAL_PRINT_STEP)))\n",
    "\n",
    "    # Data\n",
    "    (labeled, n_labeled_batches) = labeled\n",
    "    (unlabeled, n_unlabeled_batches) = unlabeled\n",
    "    (validation, n_val_batches) = validation\n",
    "\n",
    "    # Iterations\n",
    "    for (iteration, x_batch, u_batch) in zip(pbar, labeled, unlabeled):\n",
    "        (x_labeled, y_labeled) = x_batch\n",
    "        (w_unlabeled, s_unlabeled) = u_batch\n",
    "        loss_labeled, loss_unlabeled, total_loss = train_step(x_labeled, y_labeled, w_unlabeled, s_unlabeled)\n",
    "\n",
    "        train_losses_labeled[iteration] = loss_labeled\n",
    "        train_losses_unlabeled[iteration] = loss_unlabeled\n",
    "        train_losses[iteration] = total_loss\n",
    "\n",
    "        optimizer.learning_rate.assign(lr_schedule(iteration))\n",
    "        pbar.set_description('Train Loss: %.6f' % total_loss)\n",
    "\n",
    "        # Validation\n",
    "        if iteration % VAL_PRINT_STEP == 0:\n",
    "            val_loss, val_accuracy = [], []\n",
    "            for (i, (x_val, y_val)) in zip(range(n_val_batches), validation):\n",
    "                val_batch_loss, val_batch_accuracy = validation_step(x_val, y_val)\n",
    "                val_loss.append(val_batch_loss)\n",
    "                val_accuracy.append(val_batch_accuracy)\n",
    "            val_loss_mean, val_accuracy_mean = np.mean(val_loss), np.mean(val_accuracy)\n",
    "            val_losses[iteration // VAL_PRINT_STEP] = val_loss_mean\n",
    "            val_accuracies[iteration // VAL_PRINT_STEP] = val_accuracy_mean\n",
    "            if plotlosses:\n",
    "                plotlosses.update({\n",
    "                    'labeled_val_loss': val_loss_mean,\n",
    "                    'val_acc': val_accuracy_mean\n",
    "                })\n",
    "\n",
    "        if plotlosses:\n",
    "            plotlosses.update({\n",
    "                'labeled_loss': loss_labeled,\n",
    "                'unlabeled_loss': loss_unlabeled,\n",
    "                'total_loss': total_loss\n",
    "            })\n",
    "\n",
    "            if iteration % VAL_PRINT_STEP == 0:\n",
    "                plotlosses.send()\n",
    "    \n",
    "    if plotlosses:\n",
    "        plotlosses.send()\n",
    "    save_download_model(model_name)\n",
    "    return train_losses_labeled, train_losses_unlabeled, train_losses, val_losses, val_accuracies\n",
    "\n",
    "def run_test(test, n_test_batches):\n",
    "    test_accuracy = []\n",
    "    for (i, (x_test, y_test)) in zip(range(n_test_batches), test):\n",
    "        logits = model(x_test, training=False)\n",
    "        predictions = tf.argmax(logits, axis=-1)\n",
    "        targets = tf.argmax(y_test, axis=-1)\n",
    "        test_batch_accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, targets), tf.float32))\n",
    "        test_accuracy.append(test_batch_accuracy)\n",
    "    return np.mean(test_accuracy)\n",
    "\n",
    "def run_test_vote(test, n_test_batches):\n",
    "    test_accuracy = []\n",
    "    for (i, (x_test, y_test)) in zip(range(n_test_batches), test):\n",
    "        logits = model(x_test, training=False)\n",
    "        predictions = tf.argmax(logits, axis=-1)\n",
    "        targets = tf.argmax(y_test, axis=-1)\n",
    "        imgs_in_batch = tf.math.floordiv(tf.gather_nd(tf.shape(predictions), [0]), repeats)\n",
    "        image_split = tf.fill((imgs_in_batch,), repeats)\n",
    "        split_preds = tf.split(predictions, image_split)\n",
    "        split_labels = tf.split(targets, image_split)\n",
    "        for (img_preds, img_labels) in zip(split_preds, split_labels):\n",
    "            y, _, count = tf.unique_with_counts(img_preds)\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.fill((1,), y[tf.argmax(count)]), img_labels), tf.float32))\n",
    "            test_accuracy.append(accuracy)\n",
    "    return tf.reduce_mean(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jrvw6VPNLmZW"
   },
   "source": [
    "## Training Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PHZBVxAqLl3B",
    "outputId": "7d4fb32c-33bb-463a-da76-709a806f9809",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27bacbd3e3e47f3baa9d23e501c4039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/erikb/.pyenv/versions/sci/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/erikb/.pyenv/versions/sci/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model_mu2/assets\n",
      "  adding: model_mu2/ (stored 0%)\n",
      "  adding: model_mu2/assets/ (stored 0%)\n",
      "  adding: model_mu2/variables/ (stored 0%)\n",
      "  adding: model_mu2/variables/variables.index (deflated 77%)\n",
      "  adding: model_mu2/variables/variables.data-00000-of-00001 (deflated 8%)\n",
      "  adding: model_mu2/saved_model.pb (deflated 93%)\n"
     ]
    }
   ],
   "source": [
    "# Hyper-params\n",
    "LAMBDA_U = 1\n",
    "TAU = 0.95\n",
    "MU = 2\n",
    "LR = 0.03\n",
    "ITERATIONS = 40000\n",
    "BATCH_SIZE = 64\n",
    "LABELS_PER_CLASS = 25\n",
    "WD = 0.00005\n",
    "VAL_PRINT_STEP = 100\n",
    "model_name = 'mu2'\n",
    "\n",
    "# Data\n",
    "NUM_VAL_SAMPLES = 1000\n",
    "num_training_samples = TOTAL_NUM_TRAIN_SAMPLES - NUM_VAL_SAMPLES\n",
    "labeled, unlabeled, validation = dataset_trainval(LABELS_PER_CLASS, BATCH_SIZE, MU, NUM_VAL_SAMPLES)\n",
    "\n",
    "# Plotting\n",
    "groups = {'LABELED_LOSS': ['labeled_loss', 'labeled_val_loss'], 'UNLABELED_LOSS': ['unlabeled_loss'], 'TOTAL_LOSS': ['total_loss'], 'ACCURACY': ['val_acc']}\n",
    "#plotlosses = PlotLosses(groups=groups)\n",
    "\n",
    "# Model and training\n",
    "sgdw = tfa.optimizers.SGDW(learning_rate=LR,\n",
    "                                momentum=0.9,\n",
    "                                nesterov=True,\n",
    "                                weight_decay=WD)\n",
    "optimizer = tfa.optimizers.MovingAverage(sgdw, average_decay=0.999)\n",
    "model = WideResNet()\n",
    "\n",
    "# Train\n",
    "train_losses_labeled, train_losses_unlabeled, train_losses, val_losses, val_accuracies = run_train(labeled, unlabeled, validation, model_name=model_name)\n",
    "\n",
    "# Save Stats\n",
    "save_download_stats(train_losses_labeled, train_losses_unlabeled, train_losses, val_losses, val_accuracies, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zv6PYq8oLw6B"
   },
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "AjMsBfofL2KN",
    "outputId": "a64c741b-b66b-437c-cd74-fdb4472c2879"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0a338630924f95b0f5cbe52d54e87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc No TTA. Mean=0.7360102732976278   std=0.0010151318472962831\n",
      "Acc TTA.    Mean=0.7439666589101156   std=0.0005436661171968534\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "repeats = 7\n",
    "samples = 3\n",
    "\n",
    "acc_no_tta = np.zeros(samples)\n",
    "acc_tta = np.zeros(samples)\n",
    "\n",
    "(test, n_test_batches) = dataset_test(batch_size)\n",
    "(test_repeat, n_test_repeat_batches) = dataset_test_vote(batch_size, repeats)\n",
    "\n",
    "for i in tqdm(range(samples)):\n",
    "    acc_no_tta[i] = run_test(test, n_test_batches)\n",
    "    acc_tta[i] = run_test_vote(test_repeat, n_test_repeat_batches)\n",
    "print(\"Acc No TTA. Mean=\" + str(acc_no_tta.mean()) + \"   std=\" + str(acc_no_tta.std()))\n",
    "print(\"Acc TTA.    Mean=\" + str(acc_tta.mean()) + \"   std=\" + str(acc_tta.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cxznjJNLGR8"
   },
   "source": [
    "# Grad-CAM Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CT3bta1e2fe_"
   },
   "outputs": [],
   "source": [
    "def find_last_conv_layer(model):\n",
    "    for layer in reversed(model.layers):\n",
    "        if len(layer.output_shape) == 4:\n",
    "            return layer\n",
    "    raise ValueError(\"Could not find conv layer. Cannot apply GradCAM.\")\n",
    "\n",
    "def make_gradcam_heatmap(images_array, model):\n",
    "    last_conv_layer = find_last_conv_layer(model)\n",
    "\n",
    "    last_conv_layer_model = Model(model.inputs, last_conv_layer.output)\n",
    "    \n",
    "\n",
    "    classifier_input = Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "\n",
    "    after_last_conv = False\n",
    "    classifier_layer_names = []\n",
    "    for layer in model.layers:\n",
    "        if after_last_conv:\n",
    "            classifier_layer_names.append(layer.name)\n",
    "        elif find_last_conv_layer(model).name == layer.name:\n",
    "            after_last_conv = True\n",
    "\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = Model(classifier_input, x)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output = last_conv_layer_model(images_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds, axis=1)\n",
    "        one_hot_mask = tf.one_hot(\n",
    "            top_pred_index,\n",
    "            preds.shape[1],\n",
    "            on_value=True,\n",
    "            off_value=False,\n",
    "            dtype=tf.bool,\n",
    "        )\n",
    "        top_class_channel = tf.boolean_mask(preds, one_hot_mask)\n",
    "\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(1, 2))\n",
    "\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "\n",
    "    for i in range(pooled_grads.shape[0]):\n",
    "        for j in range(pooled_grads.shape[-1]):\n",
    "            last_conv_layer_output[i, :, :, j] *= pooled_grads[i, j]\n",
    "\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    max_heatmap = np.maximum(heatmap, 0)\n",
    "    for i in range(pooled_grads.shape[0]):\n",
    "        heatmap[i] = max_heatmap[i] / np.max(heatmap[i])\n",
    "        \n",
    "    return heatmap\n",
    "\n",
    "def combine_heatmap_image(image_array, heatmap):\n",
    "    image_array = np.uint8(255 * image_array)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "\n",
    "    superimposed_imgs = np.zeros(image_array.shape)\n",
    "    for i, (hm, im) in enumerate(zip(heatmap, image_array)):\n",
    "        jet_heatmap = jet_colors[hm]\n",
    "\n",
    "        jet_heatmap = array_to_img(jet_heatmap)\n",
    "        jet_heatmap = jet_heatmap.resize((image_array.shape[1], image_array.shape[2]))\n",
    "        jet_heatmap = img_to_array(jet_heatmap)\n",
    "\n",
    "        superimposed_img = jet_heatmap * 0.4 + im\n",
    "        superimposed_img = array_to_img(superimposed_img)\n",
    "        superimposed_imgs[i] = superimposed_img\n",
    "    \n",
    "    return superimposed_imgs / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ1jlkB-LdPd"
   },
   "source": [
    "## Grad-CAM Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PRnrULbBUBir"
   },
   "outputs": [],
   "source": [
    "# Get Dataset\n",
    "(test_grad, n_test_grad_batches) = dataset_test_gradcam(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "fWZw08pXG_i2",
    "outputId": "1d7cfd5b-e12b-41b4-b6eb-7b8c8468701d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label:        dog\n",
      "Weak prediction:   cat\n",
      "Strong prediction: dog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(w_a, s_a, labels) = next(iter(tfds.as_numpy(test_grad.unbatch().batch(1).take(1))))\n",
    "heatmap_w = make_gradcam_heatmap(w_a, model)\n",
    "heatmap_s = make_gradcam_heatmap(s_a, model)\n",
    "heatmap_w_img = combine_heatmap_image(w_a, heatmap_w)\n",
    "heatmap_s_img = combine_heatmap_image(s_a, heatmap_s)\n",
    "\n",
    "f, axarr = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "axarr[0,0].imshow(w_a[0])\n",
    "axarr[0,1].imshow(s_a[0])\n",
    "axarr[1,0].imshow(heatmap_w_img[0])\n",
    "axarr[1,1].imshow(heatmap_s_img[0])\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "print(\"True label:        \" + classes[np.argmax(labels, axis=1)[0]])\n",
    "print(\"Weak prediction:   \" + classes[np.argmax(model(w_a), axis=1)[0]])\n",
    "print(\"Strong prediction: \" + classes[np.argmax(model(s_a), axis=1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FixMatch MAIN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "sci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
